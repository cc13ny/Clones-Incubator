1
00:00:00,025 --> 00:00:02,050
[声音]

2
00:00:05,280 --> 00:00:06,000
各位你好

3
00:00:06,000 --> 00:00:09,900
欢迎再次回到异质并行编程课

4
00:00:09,900 --> 00:00:11,260
恭喜

5
00:00:11,260 --> 00:00:16,630
你们已经完成了并行编程
所有必要的基础部分

6
00:00:16,630 --> 00:00:21,900
而我们已经完成了所有
目前为止基于CUDA的东西

7
00:00:21,900 --> 00:00:25,050
而现在我们事实上
在这门课非常有趣的阶段

8
00:00:25,050 --> 00:00:30,130
我们将会另辟蹊径到
相关的编程模型和允许你去

9
00:00:30,130 --> 00:00:32,540
将会允许你去应用

10
00:00:32,540 --> 00:00:37,540
一些技术到这些其他编程模型

11
00:00:37,540 --> 00:00:41,600
你将会很快意识到那些概念和技巧是

12
00:00:41,600 --> 00:00:45,910
非常一样的 只是通过
额外的理解

13
00:00:45,910 --> 00:00:50,520
到相关的模型可以容易地修改所有你

14
00:00:50,520 --> 00:00:54,720
在这门课已经学到的到其他编程模型

15
00:00:54,720 --> 00:00:55,190
所以我们将会

16
00:00:55,190 --> 00:00:57,390
开始OpenCL和我们将会

17
00:00:57,390 --> 00:01:01,940
通过讨论OpenCL数据并行模型开始

18
00:01:01,940 --> 00:01:06,720
这节课的目标是让你去
了解OpenCL编程模型

19
00:01:06,720 --> 00:01:10,290
我们将会复习基本的概念和数据类型
和我们将会

20
00:01:10,290 --> 00:01:14,670
介绍内核的结构 和接着我们将会
开始讨论一些

21
00:01:14,670 --> 00:01:17,470
应用编程程序接口函数

22
00:01:17,470 --> 00:01:20,710
接着我们将会有一些各种各样的例子

23
00:01:22,680 --> 00:01:27,850
OpenCL是由苹果(Apple)公司发起的
和由Khronos组维护

24
00:01:27,850 --> 00:01:30,000
Khronos组是个标准组

25
00:01:30,000 --> 00:01:34,090
它也存着OpenCL标准和诸如此类

26
00:01:34,090 --> 00:01:35,650
而这被发展为

27
00:01:35,650 --> 00:01:39,470
一个行业标准应用程序接口

28
00:01:39,470 --> 00:01:43,830
所以不像CUDA 
OpenCL从最开始被设计为

29
00:01:43,830 --> 00:01:48,350
成一个将被多个公司执行的标准

30
00:01:48,350 --> 00:01:52,212
包括英伟达(Nvidia)和超微设备(AMD)

31
00:01:56,190 --> 00:02:00,030
英特尔(Intel)和Zylink诸如此类

32
00:02:00,030 --> 00:02:03,560
所以有着公司实际上产生

33
00:02:03,560 --> 00:02:09,200
相当种类多样的不同计算设备
以及OpenCL被

34
00:02:09,200 --> 00:02:13,030
设计成对于它们全部能够实施

35
00:02:13,030 --> 00:02:15,510
于同一个编程接口 那么相同的

36
00:02:15,510 --> 00:02:19,332
代码键将能够执行在
所有这些不同的设备

37
00:02:19,332 --> 00:02:21,430
所以OpenCL大量利用了CUDA

38
00:02:21,430 --> 00:02:26,520
因为OpenCL在CUDA之后设计
而大量的

39
00:02:26,520 --> 00:02:31,225
概念和技术已经在CUDA之中被证明了

40
00:02:31,225 --> 00:02:37,070
所以OpenCL事实上在规范中
借用了很多那些东西

41
00:02:37,070 --> 00:02:43,340
所以作为结果 作为一名CUDA编程员
去学习OpenCL真的相当容易

42
00:02:43,340 --> 00:02:46,480
那是我们先教CUDA的部分原因

43
00:02:46,480 --> 00:02:48,840
因为一旦你了解CUDA 你将会

44
00:02:48,840 --> 00:02:51,769
有能力去非常容易地去理解OpenCL

45
00:02:53,040 --> 00:02:58,740
然而OpenCL主机代码
复杂和乏味得多 因为有着需要


46
00:02:58,740 --> 00:03:04,950
去最大化可移植性和
减少供应商实现的负担


47
00:03:04,950 --> 00:03:08,700
所以那也是我们教CUDA的部分原因

48
00:03:08,700 --> 00:03:11,460
因为一旦我们了解了所有基本概念


49
00:03:11,460 --> 00:03:16,220
接着我们可以容易地采取


50
00:03:16,220 --> 00:03:21,460
另一步 了解一些乏味的 更乏味的


51
00:03:22,600 --> 00:03:27,520
OpenCL主机代码的方面

52
00:03:27,520 --> 00:03:31,692
所以让我们开始OpenCL程序的基本结构

53
00:03:31,692 --> 00:03:33,830
一个OpenCL程序是一个C程序


54
00:03:33,830 --> 00:03:37,900
它包含着一个或多个内核以及任何

55
00:03:37,900 --> 00:03:40,800
可以在目标设备运行的辅助程序

56
00:03:40,800 --> 00:03:45,100
所以这是一种非常简单的例子



57
00:03:45,100 --> 00:03:48,720
OpenCL程序里包含多个内核

58
00:03:48,720 --> 00:03:52,540
一个或者多个这些内核和
接着在设备上的辅助函数

59
00:03:52,540 --> 00:03:57,740
显然地它们也包括非常多主机代码

60
00:03:57,740 --> 00:04:03,300
将执行在CPU
而一个OpenCL内核是一个

61
00:04:03,300 --> 00:04:05,620
并行代码的基本单元
就像CUDA内核一样

62
00:04:05,620 --> 00:04:09,340
所以我们可以容易地只是
改变这张图到CUDA

63
00:04:09,340 --> 00:04:11,730
通过把一个CUDA程序放在这里

64
00:04:11,730 --> 00:04:14,460
然后所有的内核A 内核B 
内核C 仍然适用

65
00:04:14,460 --> 00:04:18,633
所以这非常像CUDA直接的等价物

66
00:04:19,960 --> 00:04:24,085
OpenCL的执行模型也和CUDA的


67
00:04:24,085 --> 00:04:29,040
极度相似 以及它集成的
主机设备应用就像CUDA的一样

68
00:04:29,040 --> 00:04:32,970
并且这串行的代码或者
并行程度比较少的代码

69
00:04:32,970 --> 00:04:37,930
以主机CPU代码的方式运行 所以
我们只是通过单个固定的线程说明

70
00:04:37,930 --> 00:04:40,628
然后高度优化的并行部分

71
00:04:40,628 --> 00:04:43,260
是在设备里运行

72
00:04:43,260 --> 00:04:47,210
这些是被展示成有着

73
00:04:47,210 --> 00:04:51,170
非常多更薄的线程以及它们运行

74
00:04:51,170 --> 00:04:54,185
在SPMD上 一个程序多个数据

75
00:04:54,185 --> 00:04:56,090
就像CUDA和C代码

76
00:04:57,350 --> 00:05:04,660
所以这里是个重要的表格
它会给你在OpenCL和

77
00:05:04,660 --> 00:05:08,760
CUDA数据并行模型概念之间的映射


78
00:05:08,760 --> 00:05:11,840
所以在左手边我们展示了OpenCL的术语

79
00:05:11,840 --> 00:05:14,800
在右手边 我们展示CUDA的等价部分

80
00:05:14,800 --> 00:05:19,410
所以在OpenCL里 一个主机对应于

81
00:05:19,410 --> 00:05:20,500
一个CUDA主机

82
00:05:20,500 --> 00:05:24,060
OpenCL设备也对应着CUDA设备

83
00:05:24,060 --> 00:05:27,350
OpenCL内核对应着CUDA内核

84
00:05:27,350 --> 00:05:31,690
一个OpenCL主机程序对应着
CUDA的主机程序

85
00:05:31,690 --> 00:05:35,570
这里的差别在于术语上的差别

86
00:05:35,570 --> 00:05:38,070
但是它们分享完全一致的概念

87
00:05:38,070 --> 00:05:45,060
NDRange的概念或者索引范围

88
00:05:45,060 --> 00:05:49,160
或者索引空间（在OpenCL里的）
对应着CUDA中的线程网格

89
00:05:49,160 --> 00:05:53,500
而在OpenCL的工作项对应着
CUDA线程

90
00:05:53,500 --> 00:05:57,570
而在OpenCL的工作组对应着
CUDA线程块


91
00:05:57,570 --> 00:06:04,450
OpenCL内核和CUDA的极度相似

92
00:06:04,450 --> 00:06:07,297
事实上对于在OpenCL内核里的

93
00:06:07,297 --> 00:06:10,436
每个概念都存在着一个直接对应在

94
00:06:10,436 --> 00:06:12,480
CUDA里面

95
00:06:12,480 --> 00:06:18,390
所以内核体也对于
每个工作项实例化一次

96
00:06:18,390 --> 00:06:24,610
所以那是为什么工作项是
CUDA线程的一个直接等价物

97
00:06:24,610 --> 00:06:29,770
而且每个OpenCL工作项
将会得到一个唯一的索引

98
00:06:29,770 --> 00:06:34,190
这里是一个简单的
实现加法的内核

99
00:06:34,190 --> 00:06:36,250
所以不是

100
00:06:36,250 --> 00:06:41,543
__global__ OpenCL内核的

101
00:06:41,543 --> 00:06:45,360
关键字是 __kernel

102
00:06:45,360 --> 00:06:51,670
而这是我会说有点合乎逻辑和
这是因为CUDA

103
00:06:51,670 --> 00:06:55,900
首先被定义 然后我们学会这种
方式是很有可能更直观

104
00:06:55,900 --> 00:07:00,880
所以OpenCL改善了
一些关键字的使用

105
00:07:00,880 --> 00:07:01,900
然后

106
00:07:01,900 --> 00:07:07,390
在那些参数里面 对于每个指向
全局内存的指针

107
00:07:07,390 --> 00:07:13,430
我们有 __global
在参数的类型声明之前

108
00:07:13,430 --> 00:07:19,030
然后在内核里面 
不是一个建好的变量给我们块索引

109
00:07:19,030 --> 00:07:27,230
和线程索引 OpenCL事实上
有着一个API函数调用

110
00:07:27,230 --> 00:07:32,890
而这个API函数调用 get_global_id
事实上获得一个

111
00:07:32,890 --> 00:07:37,840
与全局索引等价的东西
所以这是

112
00:07:37,840 --> 00:07:42,640
真的等价于 CUDA里的
blockIndex.x 乘以

113
00:07:42,640 --> 00:07:47,680
blockDim.x 加 threadIdx.x.
所以这

114
00:07:47,680 --> 00:07:52,690
单一的函数调用帮我们
得到了全局线程索引

115
00:07:52,690 --> 00:07:55,900
实际上跨过整个网格

116
00:07:55,900 --> 00:07:59,660
所以在每个维度 0意味着x维度

117
00:07:59,660 --> 00:08:02,220
所以你应该期望如果你需要

118
00:08:02,220 --> 00:08:10,330
知道y维度的全局id
那将是get_global_id(1)

119
00:08:10,330 --> 00:08:13,890
所以我们一旦有了全局索引 我们能

120
00:08:13,890 --> 00:08:18,160
只是用全局索引去访问a和b

121
00:08:18,160 --> 00:08:25,010
（这两个）输入数组和
写入c数组里面 所以如果我们看

122
00:08:25,010 --> 00:08:30,970
一种概念图 我们看到所有工作项

123
00:08:30,970 --> 00:08:36,850
组成工作组 所以在这个小例子里
我们有着八个工作项

124
00:08:36,850 --> 00:08:42,080
在每个工作组里面 以及我们有
八个工作组在图里面

125
00:08:42,080 --> 00:08:43,180
然后

126
00:08:43,180 --> 00:08:48,700
所有工作项执行完全一样的代码段
所以这是

127
00:08:48,700 --> 00:08:54,610
SPMD（一个项目多个数据） 
然后每个工作项将会调用get_global_id

128
00:08:54,610 --> 00:09:00,140
(0) 以便得到全局x维度的索引

129
00:09:00,140 --> 00:09:04,230
所以在这次调用以后 
所有工作项得到

130
00:09:04,230 --> 00:09:08,280
在这图里唯一的一个号码 
从0到7

131
00:09:08,280 --> 00:09:14,330
在第一个工作组里 从8到15在
第二个工作组里 然后从56一直

132
00:09:14,330 --> 00:09:20,830
到63在最后一个工作组里
在这例子里面

133
00:09:20,830 --> 00:09:24,540
所以通过一次调用 你得到一个

134
00:09:24,540 --> 00:09:27,490
对于全工作组唯一的ID

135
00:09:27,490 --> 00:09:32,440
然后你可以只是用那ID
去索引你的输入数据结构

136
00:09:32,440 --> 00:09:33,540
所以这事实上

137
00:09:33,540 --> 00:09:39,650
是个非常方便的机制去得到一个
非常小和简单的运行的内核

138
00:09:41,530 --> 00:09:44,290
所以我想说一些关于工作组的

139
00:09:44,290 --> 00:09:48,520
工作组是线程块的直接对应

140
00:09:48,520 --> 00:09:54,420
实际上分割单片的
工作项数组成工作组

141
00:09:54,420 --> 00:09:58,540
所以这是和CUDA非常非常相似

142
00:09:58,540 --> 00:10:01,310
OpenCL也有两级层次

143
00:10:02,580 --> 00:10:06,830
你有被块分割的网格和块包含着线程

144
00:10:06,830 --> 00:10:10,870
这里我们有NDRange
被分割成工作组

145
00:10:10,870 --> 00:10:13,500
而工作组包含着工作项

146
00:10:13,500 --> 00:10:15,390
所以所有在一个工作组里的工作项

147
00:10:15,390 --> 00:10:18,670
可合作于共享内存和屏障同步

148
00:10:18,670 --> 00:10:21,090
就像在一个线程

149
00:10:21,090 --> 00:10:23,590
在线程块里
线程项在不同的工作组里

150
00:10:23,590 --> 00:10:29,360
不能合作 以及这允许透明的延伸性

151
00:10:29,360 --> 00:10:35,370
就像CUDA线程块
所以不是建立变量

152
00:10:35,370 --> 00:10:41,745
像一个blockIdx.x-y-z
blockDim.x-y-z和诸如此类

153
00:10:41,745 --> 00:10:47,160
OpenCL通过API支持这些值


154
00:10:47,160 --> 00:10:48,770
所以你可以调用API

155
00:10:48,770 --> 00:10:51,330
get_global_id.

156
00:10:51,330 --> 00:10:56,270
然后你可以提供0 1 2 
相当于x y z

157
00:10:56,270 --> 00:11:00,220
然后这将会给你工作项
在x维度里全局的索引

158
00:11:00,220 --> 00:11:02,150
这是跨越全部

159
00:11:02,150 --> 00:11:03,030
工作组

160
00:11:03,030 --> 00:11:11,110
所以这真的是等同于blockIdx.x
乘以blockDim.x加上threadIdx.x.

161
00:11:11,110 --> 00:11:14,360
所以那是我们如何产生
全局线程索引

162
00:11:14,360 --> 00:11:17,400
给一个CUDA线程

163
00:11:17,400 --> 00:11:23,360
你们那些对产生

164
00:11:23,360 --> 00:11:27,280
一个本地索引感兴趣的
也就是对于工作项产生一个

165
00:11:27,280 --> 00:11:31,870
在工作组里的本地索引
相当于threadIdx.x

166
00:11:31,870 --> 00:11:36,460
这是你可以使用的方法
调用get_local_id(0)

167
00:11:36,460 --> 00:11:39,990
而每一个都有一个下划线在它们之间

168
00:11:39,990 --> 00:11:44,870
所以这是实际上给了我们所想的
那个工作组的索引

169
00:11:44,870 --> 00:11:49,680
然后对于你们想知道

170
00:11:49,680 --> 00:11:54,370
网格线的维度

171
00:11:54,370 --> 00:11:57,490
网格线在每个维度的大小以及
工作组在每个维度的大小

172
00:11:57,490 --> 00:12:02,280
两者都是以工作项的数量
为测量标准

173
00:12:02,280 --> 00:12:04,790
然后我们可以调用
get_global_size

174
00:12:05,850 --> 00:12:06,430
(0)

175
00:12:06,430 --> 00:12:11,070
所以这将会给我们在x维度
任何范围的大小

176
00:12:11,070 --> 00:12:14,273
这相当于gridDim.x乘以

177
00:12:14,273 --> 00:12:20,556
blockDim.x在CUDA里面 以及如果
我们调用get_local_size(0) 那

178
00:12:20,556 --> 00:12:26,630
将等价于blockDim.x
所以如果你们想得到CUDA的

179
00:12:29,100 --> 00:12:35,490
gridDim.x的等价物 然后你们
事实上只要调用get_global_size

180
00:12:35,490 --> 00:12:40,020
除以那个你通过get_local_size
得到的值 那么它将会给你

181
00:12:40,020 --> 00:12:45,720
网格线中每个维度的工作项的数量

182
00:12:47,940 --> 00:12:50,810
这里是个非常简单的例子

183
00:12:50,810 --> 00:12:56,130
它说明了多维度工作项索引
是如何工作的

184
00:12:56,130 --> 00:13:01,010
所以我们看到实际上这线程

185
00:13:01,010 --> 00:13:05,660
这结束范围将会是一个
两维的数组和每个线程将会

186
00:13:05,660 --> 00:13:09,400
是数组里的其中一个元素

187
00:13:09,400 --> 00:13:13,030
以及那个数组也将会被分割成

188
00:13:13,030 --> 00:13:14,320
这四个组

189
00:13:14,320 --> 00:13:17,480
所以我们看到那 我们可以得到

190
00:13:17,480 --> 00:13:23,300
在每个方向工作组的数量 
通过调用GlobalSize

191
00:13:23,300 --> 00:13:26,380
而0意味着x和1意味着y

192
00:13:26,380 --> 00:13:28,720
明显地 2将会是z

193
00:13:28,720 --> 00:13:35,290
在每个工作组里面 我们可以调用
LocalSize(0)和LocalSize(1)

194
00:13:35,290 --> 00:13:38,200
去得到在工作组每个方向里

195
00:13:38,200 --> 00:13:40,430
工作项的数目

196
00:13:40,430 --> 00:13:46,090
对于每个组  我们可以调用

197
00:13:46,090 --> 00:13:51,920
我们可以得到组ID以及我们可以通过
实际上我们可以调用

198
00:13:51,920 --> 00:13:56,918
我们可以为每个线程得到组ID
和接着我们也可以得到

199
00:13:56,918 --> 00:14:02,340
一个工作组里的
每个工作项的本地ID

200
00:14:05,420 --> 00:14:09,970
所以让我们对OpenCL数据
并行执行模型做出总结

201
00:14:09,970 --> 00:14:14,590
并行的工作通过启动内核
被提交到设备上 就像CUDA一样

202
00:14:14,590 --> 00:14:18,250
内核运行遍全局维度的

203
00:14:18,250 --> 00:14:24,060
索引范围(NDRange) 
而它们被分成工作组和工作项

204
00:14:24,060 --> 00:14:27,170
而执行于相同

205
00:14:27,170 --> 00:14:30,810
工作组里的工作项可以
相互间与各个

206
00:14:30,810 --> 00:14:33,970
围栏或者内存栅栏同步 
就像CUDA线程块一样

207
00:14:33,970 --> 00:14:37,600
而在不同工作组的工作项
相互之间不能同步

208
00:14:37,600 --> 00:14:40,770
而除了当你终止一个内核的时候

209
00:14:40,770 --> 00:14:46,000
就像线程在CUDA内核里的情形一样



210
00:14:47,170 --> 00:14:50,645
所以此刻你有着对

211
00:14:50,645 --> 00:14:56,250
OpenCL非常基本的理解
你确切地知道如何写一个简单向量相加内核（函数）

212
00:14:56,250 --> 00:15:01,600
想学的更多的话 我会建议你去读教程

213
00:15:01,600 --> 00:15:06,981
章节14.1和14.2
谢谢你们
